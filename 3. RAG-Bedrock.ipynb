{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ec665b-19e2-412c-838f-619d8dbdcc69",
   "metadata": {},
   "source": [
    "# Introduction to RAG with Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "086a6ca2-32c7-41ad-9039-b339568ecc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa2e51e3-90f8-463c-a387-475f7576a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AWS Bedrock client\n",
    "bedrock=boto3.client(service_name=\"bedrock-runtime\")\n",
    "bedrock_embeddings=BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\",client=bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bb6bd88-97ac-4ec9-9bf6-6895412e856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data ingestion\n",
    "def data_ingestion():\n",
    "    loader=PyPDFDirectoryLoader(\"data\")\n",
    "    documents=loader.load()\n",
    "    \n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=10000,\n",
    "                                                 chunk_overlap=1000)\n",
    "    \n",
    "    docs=text_splitter.split_documents(documents)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "134cc168-e481-4706-b905-9f1b51dea6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector Embedding and vector store\n",
    "def get_vector_store(docs):\n",
    "    vectorstore_faiss=FAISS.from_documents(\n",
    "        docs,\n",
    "        bedrock_embeddings\n",
    "    )\n",
    "    vectorstore_faiss.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e92be69-fbfd-4eb2-818e-38f61eff5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama3_llm():\n",
    "    ##create the Anthropic Model\n",
    "    llm=Bedrock(model_id=\"meta.llama3-8b-instruct-v1:0\",client=bedrock,\n",
    "                model_kwargs={'max_gen_len':512})\n",
    "    \n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3875d173-4e4a-47cb-8970-5e2e809d85bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "\n",
    "Human: Use the following pieces of context to provide a \n",
    "concise answer to the question at the end but use atleast summarize with \n",
    "250 words with detailed explainations. If you don't know the answer, \n",
    "just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2acaeb05-672a-471d-9c3a-2b6165e3785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7b9ef9c-5fde-4d3a-96ba-1f68dae9e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_llm(llm,vectorstore_faiss,query):\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm,chain_type=\"stuff\",\n",
    "                                     retriever=vectorstore_faiss.as_retriever(search_type=\"similarity\", \n",
    "                                                                              search_kwargs={\"k\": 3}),\n",
    "                                     return_source_documents=True,chain_type_kwargs={\"prompt\": PROMPT})\n",
    "    answer=qa({\"query\":query})\n",
    "    return answer['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "238f3166-1fec-4e72-941c-c768dd6aa74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    user_question = \"summary please\"\n",
    "    docs = data_ingestion()\n",
    "    get_vector_store(docs)\n",
    "    faiss_index = FAISS.load_local(\"faiss_index\", bedrock_embeddings,allow_dangerous_deserialization=True)\n",
    "    llm=get_llama3_llm()\n",
    "    #faiss_index = get_vector_store(docs)\n",
    "    print(get_response_llm(llm,faiss_index,user_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61610926-3379-4314-a9d9-e720b147ccf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "Based on the provided context, I will summarize the main points and provide a concise answer to the question. \n",
      "\n",
      "The provided context is a collection of research papers and articles related to neural network-based video compression. The papers discuss various techniques and models for compressing video data using neural networks, including autoencoders, transformers, and quantization methods. The context also includes information about the UVG and MCL-JVC datasets, which are used for evaluating the performance of video compression algorithms. \n",
      "\n",
      "The question is not explicitly stated in the provided context, but based on the content, it appears to be related to the topic of neural network-based video compression. Therefore, I will provide a summary of the main points and highlight some of the key findings and techniques discussed in the context. \n",
      "\n",
      "The main points discussed in the context are:\n",
      "\n",
      "1. The use of neural networks for video compression, including autoencoders and transformers.\n",
      "2. The importance of quantization in neural network-based video compression.\n",
      "3. The use of datasets such as UVG and MCL-JVC for evaluating the performance of video compression algorithms.\n",
      "4. The development of new models and techniques for compressing video data using neural networks.\n",
      "\n",
      "Some of the key findings and techniques discussed in the context include:\n",
      "\n",
      "1. The use of autoencoders for compressing video data, which can achieve better compression ratios than traditional methods.\n",
      "2. The use of transformers for compressing video data, which can achieve better compression ratios than autoencoders.\n",
      "3. The importance of quantization in neural network-based video compression, which can affect the performance of the algorithm.\n",
      "4. The use of datasets such as UVG and MCL-JVC for evaluating the performance of video compression algorithms.\n",
      "\n",
      "Overall, the context provides a comprehensive overview of the current state of research in neural network-based video compression, including the techniques and models used, the importance of quantization, and the use of datasets for evaluating performance. \n",
      "\n",
      "If you would like me to answer a specific question based on the context, please let me know and I will do my best to provide a concise and accurate answer. \n",
      "\n",
      "Please let me know if you would like me to summarize the context in a different way or if you have any further questions. \n",
      "\n",
      "Please provide the specific question you would like me to answer, and I will do my best to provide a concise and accurate answer. \n",
      "\n",
      "Please note that the context provided is quite extensive, and it may take some time to summarize it. \n",
      "\n",
      "Please let me know if you have any further questions or if there\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43082a9f-ca8e-4853-8216-9db3389db02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
